{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item - Item Collaborative Filtering Model\n",
    " After initially starting this project thinking that the customer based collaborative filtering model was the way to go, I slowly realised that an item-item filtering would be better for the following reasons:\n",
    " 1. The number of products a company has is finite while the number of customers is potentially infinite.\n",
    " 2. If I visualise the products connected to each other, you can see clustering when it comes to category and other product attributes.\n",
    " 3. Most importantly, this particular dataset has 91,000 unique customers and only 31,000 unique products. This means:\n",
    "   - more connections between the products as they have more frequency of purchase\n",
    "   - 30 times shorter calculation time for the full product set (64 days versus 1,895)\n",
    "   - smaller file size for storage\n",
    "  \n",
    "  The methodology used is basically the same\n",
    "  \n",
    "This notebook goes through the steps needed to create the model and any code for the accompanying app:\n",
    "1. Importing Libraries and data\n",
    "2. TFIDF Vectorizer\n",
    "3. Singular Value Decomposition\n",
    "4. Cosine Similarity Calculation\n",
    "5. Making Recommendations\n",
    "6. Network Visualisation\n",
    "7. Web Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Relevant Libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import barnum\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "# import warnings\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/cleaned-df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create initial product and customer lists for formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_names = list(df.customer_name.unique())\n",
    "prod_names = list(df.product_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_sales = df.apply(lambda x: list([x['customer_name'], x['product_name']]),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of a dictionary with all the products and the customers that purchased them\n",
    "prod_cust = {}\n",
    "for cust, prod in prod_sales:\n",
    "    prod_cust.setdefault(prod, set()).add(cust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_lists = {k:list(prod_cust[k]) for k in list(prod_cust)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust the dictionary to be able to be used by the TFIDF vectorizer\n",
    "prod_vecs = pd.Series(prod_lists)\n",
    "prod_vecs = prod_vecs.apply(lambda x : [', '.join(x) for word in [x]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "limit Lisa           Jarod Morrow, Palmer Bankston, Genaro Cheatham...\n",
       "archeology curler    Major Geer, Blake Thomason, Vikki Torrez, Inez...\n",
       "aunt leg                  Carla Dellinger, Betty Nestor, Chris Baldwin\n",
       "rotate macrame       Elden Eddy, Caren Whitt, Billie Millard, Laver...\n",
       "apple lentil         Catharine Mancini, Tracy Dupre, Hazel Chester,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_vecs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of TFIDF dataframe for comparison of products and the customers that purchased them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(lowercase = False, ngram_range=(1,2),vocabulary=cust_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_tfidfvecs =  pd.DataFrame(tfidf.fit_transform(prod_vecs).todense(),columns=tfidf.get_feature_names())                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_tfidfvecs.set_index(prod_vecs.index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rodrigo Keefe</th>\n",
       "      <th>Julianna Queen</th>\n",
       "      <th>Palmer Bankston</th>\n",
       "      <th>Lupe Pettigrew</th>\n",
       "      <th>Genaro Cheatham</th>\n",
       "      <th>Rod Nesbitt</th>\n",
       "      <th>Jarod Morrow</th>\n",
       "      <th>Betty Nestor</th>\n",
       "      <th>Ellis Whittle</th>\n",
       "      <th>Major Geer</th>\n",
       "      <th>...</th>\n",
       "      <th>Armando Adams</th>\n",
       "      <th>Ursula Christie</th>\n",
       "      <th>Seymour Hutchens</th>\n",
       "      <th>Owen Curtin</th>\n",
       "      <th>Bernadette Burgess</th>\n",
       "      <th>Shad Stroud</th>\n",
       "      <th>Elvis Fisher</th>\n",
       "      <th>Elvia Bell</th>\n",
       "      <th>Jana Horsley</th>\n",
       "      <th>Hattie Olivas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>limit Lisa</td>\n",
       "      <td>0.334724</td>\n",
       "      <td>0.334724</td>\n",
       "      <td>0.334724</td>\n",
       "      <td>0.334724</td>\n",
       "      <td>0.334724</td>\n",
       "      <td>0.334724</td>\n",
       "      <td>0.334724</td>\n",
       "      <td>0.321992</td>\n",
       "      <td>0.334724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>archeology curler</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aunt leg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rotate macrame</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>apple lentil</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ceramic barber</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cafe advertisement</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gum chronometer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>segment ocean</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>grip decade</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 91593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Rodrigo Keefe  Julianna Queen  Palmer Bankston  \\\n",
       "limit Lisa               0.334724        0.334724         0.334724   \n",
       "archeology curler        0.000000        0.000000         0.000000   \n",
       "aunt leg                 0.000000        0.000000         0.000000   \n",
       "rotate macrame           0.000000        0.000000         0.000000   \n",
       "apple lentil             0.000000        0.000000         0.000000   \n",
       "ceramic barber           0.000000        0.000000         0.000000   \n",
       "cafe advertisement       0.000000        0.000000         0.000000   \n",
       "gum chronometer          0.000000        0.000000         0.000000   \n",
       "segment ocean            0.000000        0.000000         0.000000   \n",
       "grip decade              0.000000        0.000000         0.000000   \n",
       "\n",
       "                    Lupe Pettigrew  Genaro Cheatham  Rod Nesbitt  \\\n",
       "limit Lisa                0.334724         0.334724     0.334724   \n",
       "archeology curler         0.000000         0.000000     0.000000   \n",
       "aunt leg                  0.000000         0.000000     0.000000   \n",
       "rotate macrame            0.000000         0.000000     0.000000   \n",
       "apple lentil              0.000000         0.000000     0.000000   \n",
       "ceramic barber            0.000000         0.000000     0.000000   \n",
       "cafe advertisement        0.000000         0.000000     0.000000   \n",
       "gum chronometer           0.000000         0.000000     0.000000   \n",
       "segment ocean             0.000000         0.000000     0.000000   \n",
       "grip decade               0.000000         0.000000     0.000000   \n",
       "\n",
       "                    Jarod Morrow  Betty Nestor  Ellis Whittle  Major Geer  \\\n",
       "limit Lisa              0.334724      0.321992       0.334724    0.000000   \n",
       "archeology curler       0.000000      0.000000       0.000000    0.288675   \n",
       "aunt leg                0.000000      0.569743       0.000000    0.000000   \n",
       "rotate macrame          0.000000      0.000000       0.000000    0.000000   \n",
       "apple lentil            0.000000      0.000000       0.000000    0.000000   \n",
       "ceramic barber          0.000000      0.000000       0.000000    0.000000   \n",
       "cafe advertisement      0.000000      0.000000       0.000000    0.000000   \n",
       "gum chronometer         0.000000      0.000000       0.000000    0.000000   \n",
       "segment ocean           0.000000      0.000000       0.000000    0.000000   \n",
       "grip decade             0.000000      0.000000       0.000000    0.000000   \n",
       "\n",
       "                    ...  Armando Adams  Ursula Christie  Seymour Hutchens  \\\n",
       "limit Lisa          ...            0.0              0.0               0.0   \n",
       "archeology curler   ...            0.0              0.0               0.0   \n",
       "aunt leg            ...            0.0              0.0               0.0   \n",
       "rotate macrame      ...            0.0              0.0               0.0   \n",
       "apple lentil        ...            0.0              0.0               0.0   \n",
       "ceramic barber      ...            0.0              0.0               0.0   \n",
       "cafe advertisement  ...            0.0              0.0               0.0   \n",
       "gum chronometer     ...            0.0              0.0               0.0   \n",
       "segment ocean       ...            0.0              0.0               0.0   \n",
       "grip decade         ...            0.0              0.0               0.0   \n",
       "\n",
       "                    Owen Curtin  Bernadette Burgess  Shad Stroud  \\\n",
       "limit Lisa                  0.0                 0.0          0.0   \n",
       "archeology curler           0.0                 0.0          0.0   \n",
       "aunt leg                    0.0                 0.0          0.0   \n",
       "rotate macrame              0.0                 0.0          0.0   \n",
       "apple lentil                0.0                 0.0          0.0   \n",
       "ceramic barber              0.0                 0.0          0.0   \n",
       "cafe advertisement          0.0                 0.0          0.0   \n",
       "gum chronometer             0.0                 0.0          0.0   \n",
       "segment ocean               0.0                 0.0          0.0   \n",
       "grip decade                 0.0                 0.0          0.0   \n",
       "\n",
       "                    Elvis Fisher  Elvia Bell  Jana Horsley  Hattie Olivas  \n",
       "limit Lisa                   0.0         0.0           0.0            0.0  \n",
       "archeology curler            0.0         0.0           0.0            0.0  \n",
       "aunt leg                     0.0         0.0           0.0            0.0  \n",
       "rotate macrame               0.0         0.0           0.0            0.0  \n",
       "apple lentil                 0.0         0.0           0.0            0.0  \n",
       "ceramic barber               0.0         0.0           0.0            0.0  \n",
       "cafe advertisement           0.0         0.0           0.0            0.0  \n",
       "gum chronometer              0.0         0.0           0.0            0.0  \n",
       "segment ocean                0.0         0.0           0.0            0.0  \n",
       "grip decade                  0.0         0.0           0.0            0.0  \n",
       "\n",
       "[10 rows x 91593 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_tfidfvecs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now I want to do an SVD on the matrix to reduce the dimensionality and therefor create closer similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10741621847906922\n",
      "(2000, 91593)\n"
     ]
    }
   ],
   "source": [
    "prod_svd = svd.fit(tfidf.fit_transform(prod_vecs)) \n",
    "\n",
    "print(prod_svd.explained_variance_ratio_.sum())\n",
    "print(prod_svd.components_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While this SVD only covers 10% of the explained variance, this is ok because most of the variance is where the products are not related to each other so this is just explaining the parts that are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_svds = pd.DataFrame(prod_svd.transform(prod_tfidfvecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to round the values in the matrix to 5 decimal places so that the similarity calculations \n",
    "#will be more efficient and will hopefully not take as long to compute\n",
    "prod_svds = prod_svds.apply(lambda x: round(x,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>prod_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00536</td>\n",
       "      <td>-0.00452</td>\n",
       "      <td>0.00215</td>\n",
       "      <td>0.00284</td>\n",
       "      <td>-0.00243</td>\n",
       "      <td>-0.00856</td>\n",
       "      <td>0.00256</td>\n",
       "      <td>-0.00004</td>\n",
       "      <td>0.00484</td>\n",
       "      <td>limit Lisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00365</td>\n",
       "      <td>0.00872</td>\n",
       "      <td>0.00173</td>\n",
       "      <td>0.00558</td>\n",
       "      <td>-0.00573</td>\n",
       "      <td>-0.00789</td>\n",
       "      <td>0.00236</td>\n",
       "      <td>0.00675</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>archeology curler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00057</td>\n",
       "      <td>-0.00838</td>\n",
       "      <td>0.00461</td>\n",
       "      <td>0.00162</td>\n",
       "      <td>-0.00712</td>\n",
       "      <td>-0.01198</td>\n",
       "      <td>-0.00304</td>\n",
       "      <td>-0.00056</td>\n",
       "      <td>0.00569</td>\n",
       "      <td>aunt leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.00964</td>\n",
       "      <td>-0.01027</td>\n",
       "      <td>0.00301</td>\n",
       "      <td>-0.00603</td>\n",
       "      <td>-0.00968</td>\n",
       "      <td>0.00678</td>\n",
       "      <td>0.00973</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>rotate macrame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00274</td>\n",
       "      <td>-0.01660</td>\n",
       "      <td>-0.00468</td>\n",
       "      <td>0.00674</td>\n",
       "      <td>0.00451</td>\n",
       "      <td>0.01203</td>\n",
       "      <td>-0.01105</td>\n",
       "      <td>-0.00731</td>\n",
       "      <td>-0.00966</td>\n",
       "      <td>apple lentil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00848</td>\n",
       "      <td>0.00748</td>\n",
       "      <td>0.00296</td>\n",
       "      <td>0.00739</td>\n",
       "      <td>0.00273</td>\n",
       "      <td>0.00053</td>\n",
       "      <td>-0.00458</td>\n",
       "      <td>-0.00320</td>\n",
       "      <td>-0.00022</td>\n",
       "      <td>ceramic barber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01435</td>\n",
       "      <td>-0.00282</td>\n",
       "      <td>0.00797</td>\n",
       "      <td>-0.00617</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>0.00358</td>\n",
       "      <td>0.00408</td>\n",
       "      <td>-0.00171</td>\n",
       "      <td>-0.00004</td>\n",
       "      <td>cafe advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01060</td>\n",
       "      <td>-0.00116</td>\n",
       "      <td>0.00424</td>\n",
       "      <td>-0.00343</td>\n",
       "      <td>0.00282</td>\n",
       "      <td>0.00330</td>\n",
       "      <td>0.00839</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.00690</td>\n",
       "      <td>gum chronometer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00713</td>\n",
       "      <td>0.00563</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>-0.00265</td>\n",
       "      <td>0.00438</td>\n",
       "      <td>-0.00613</td>\n",
       "      <td>0.00517</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>-0.00246</td>\n",
       "      <td>segment ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01413</td>\n",
       "      <td>-0.00420</td>\n",
       "      <td>0.00572</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>-0.00287</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>-0.00056</td>\n",
       "      <td>0.00910</td>\n",
       "      <td>-0.00383</td>\n",
       "      <td>grip decade</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4        5    6        7        8        9  ...  \\\n",
       "0 -0.0 -0.0 -0.0  0.0  0.0 -0.00001 -0.0 -0.00001  0.00002 -0.00002  ...   \n",
       "1  0.0 -0.0 -0.0 -0.0 -0.0 -0.00000  0.0  0.00000  0.00000  0.00000  ...   \n",
       "2 -0.0 -0.0 -0.0  0.0 -0.0 -0.00001 -0.0 -0.00001  0.00002 -0.00002  ...   \n",
       "3 -0.0  0.0 -0.0  0.0  0.0  0.00000 -0.0  0.00000 -0.00001  0.00000  ...   \n",
       "4 -0.0  0.0  0.0  0.0 -0.0 -0.00000 -0.0 -0.00000  0.00000 -0.00001  ...   \n",
       "5 -0.0 -0.0 -0.0  0.0 -0.0  0.00000  0.0  0.00000  0.00001  0.00001  ...   \n",
       "6 -0.0  0.0 -0.0  0.0 -0.0 -0.00000  0.0 -0.00001 -0.00000 -0.00000  ...   \n",
       "7 -0.0 -0.0  0.0  0.0 -0.0  0.00000  0.0 -0.00000 -0.00001 -0.00001  ...   \n",
       "8 -0.0  0.0 -0.0 -0.0  0.0  0.00000 -0.0  0.00000  0.00000 -0.00000  ...   \n",
       "9 -0.0  0.0 -0.0  0.0 -0.0 -0.00000  0.0 -0.00001  0.00000 -0.00000  ...   \n",
       "\n",
       "      1991     1992     1993     1994     1995     1996     1997     1998  \\\n",
       "0 -0.00536 -0.00452  0.00215  0.00284 -0.00243 -0.00856  0.00256 -0.00004   \n",
       "1 -0.00365  0.00872  0.00173  0.00558 -0.00573 -0.00789  0.00236  0.00675   \n",
       "2 -0.00057 -0.00838  0.00461  0.00162 -0.00712 -0.01198 -0.00304 -0.00056   \n",
       "3 -0.00665 -0.00964 -0.01027  0.00301 -0.00603 -0.00968  0.00678  0.00973   \n",
       "4  0.00274 -0.01660 -0.00468  0.00674  0.00451  0.01203 -0.01105 -0.00731   \n",
       "5 -0.00848  0.00748  0.00296  0.00739  0.00273  0.00053 -0.00458 -0.00320   \n",
       "6 -0.01435 -0.00282  0.00797 -0.00617 -0.00488  0.00358  0.00408 -0.00171   \n",
       "7 -0.01060 -0.00116  0.00424 -0.00343  0.00282  0.00330  0.00839  0.00994   \n",
       "8  0.00713  0.00563  0.00044 -0.00265  0.00438 -0.00613  0.00517  0.00100   \n",
       "9 -0.01413 -0.00420  0.00572  0.00222 -0.00287  0.00156 -0.00056  0.00910   \n",
       "\n",
       "      1999          prod_names  \n",
       "0  0.00484          limit Lisa  \n",
       "1 -0.00001   archeology curler  \n",
       "2  0.00569            aunt leg  \n",
       "3  0.00196      rotate macrame  \n",
       "4 -0.00966        apple lentil  \n",
       "5 -0.00022      ceramic barber  \n",
       "6 -0.00004  cafe advertisement  \n",
       "7  0.00690     gum chronometer  \n",
       "8 -0.00246       segment ocean  \n",
       "9 -0.00383         grip decade  \n",
       "\n",
       "[10 rows x 2001 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_svds['prod_names'] = prod_names\n",
    "\n",
    "prod_svds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9340011391985048"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(prod_svds[prod_svds.prod_names == 'limit Lisa'].iloc[:,0:-1],\n",
    "                            prod_svds[prod_svds.prod_names == 'aunt leg'].iloc[:,0:-1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for initializing the dictionary\n",
    "# prod_cosine = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for adding to the pre-saved dictionary\n",
    "prod_cosine = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I want to start with the most popular products for my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_counts = df['product_name'].value_counts()\n",
    "top_100_prod = col_counts[0:100].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_800_prod = col_counts[700:800].index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of a dictionary of the related cosine scores between a product and every other product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [5:57:38<00:00, 219.35s/it] \n"
     ]
    }
   ],
   "source": [
    "for prod in tqdm(top_800_prod):\n",
    "    cosine_scores = {}\n",
    "    for n in prod_cust:\n",
    "        cosine_scores[n] = cosine_similarity(prod_svds[prod_svds.prod_names == prod].iloc[:,0:-1],\n",
    "                                             prod_svds[prod_svds.prod_names == n].iloc[:,0:-1])[0][0]\n",
    "    prod_cosine[prod] = cosine_scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prod_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Saving to json for storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/prod_cosine.json', 'w') as fp:\n",
    "    json.dump(prod_cosine, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./web_application/datasets/prod_cosine.json', 'r') as fp:\n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['limit Lisa', 'archeology curler', 'aunt leg', 'rotate macrame', 'apple lentil', 'ceramic barber', 'cafe advertisement', 'gum chronometer', 'segment ocean', 'grip decade', 'January physician', 'stop radio', 'back cowbell', 'butane crocodile', 'rose Abyssinian', 'broker ethernet', 'battery letter', 'cause hedge', 'idea meteorology', 'mother house', 'Brian Sagittarius', 'port captain', 'agreement pentagon', 'path smash', 'metal lyric', 'mistake year', 'sturgeon environment', 'tent football', 'conifer exchange', 'resolution wing', 'raven neck', 'criminal ping', 'top battery', 'cinema booklet', 'basement orchestra', 'stretch musician', 'volcano Europe', 'Dorothy geranium', 'orchid thing', 'toast engine', 'patch thrill', 'brush feeling', 'beautician patch', 'pimple schedule', 'gondola hook', 'dogsled room', 'beet meter', 'menu note', 'pancreas anger', 'skiing pan', 'porch butcher', 'roast desk', 'epoxy interest', 'noise accelerator', 'kitchen copyright', 'Aries great-grandfather', 'cycle lawyer', 'area beam', 'ophthalmologist debt', 'October tortoise', 'interest salesman', 'rubber Antarctica', 'bag Libra', 'stomach lotion', 'face begonia', 'Russian invention', 'coast semicolon', 'cover surname', 'Linda match', 'help authority', 'comfort degree', 'layer puma', 'fir police', 'beast sociology', 'burn knife', 'income seal', 'sack Iraq', 'bottom religion', 'ounce train', 'wallaby scanner', 'John Cancer', 'attempt Christopher', 'pest care', 'ankle Donna', 'grey time', 'match verse', 'hardcover saw', 'son hyena', 'hyena cabinet', 'potato sandwich', 'armed story', 'cover side', 'north soup', 'nail lettuce', 'John pie', 'study lunch', 'flame Thomas', 'taxi shrimp', 'alligator fish', 'output cardigan', 'Pisces colony', 'value limit', 'orchid equipment', 'secretary elephant', 'moat Jason', 'donkey surgeon', 'seeder defense', 'napkin harp', 'smile math', 'distance dredger', 'cause point', 'June pansy', 'memory John', 'society grease', 'skate David', 'May recess', 'son peak', 'pumpkin difference', 'refund boat', 'bakery bail', 'alligator columnist', 'Argentina asterisk', 'drop religion', 'brush March', 'base desire', 'underpants stool', 'drive distributor', 'Mark larch', 'word difference', 'engineer owl', 'song Christopher', 'quill freezer', 'top workshop', 'illegal suit', 'quiet sundial', 'suggestion sidewalk', 'Fahrenheit swamp', 'ball lathe', 'lawyer distribution', 'environment danger', 'bee arrow', 'Aries marble', 'north supermarket', 'turnip plot', 'colt coat', 'lipstick front', 'hamburger handicap', 'Sphynx India', 'museum join', 'sword headlight', 'smile sampan', 'supermarket change', 'scale slice', 'dragonfly timer', 'Kevin stem', 'cappelletti tank', 'control processing', 'sea plant', 'fork faucet', 'close dad', 'study father', 'link karate', 'note pot', 'lamp agenda', 'scarecrow statement', 'protocol soap', 'time apple', 'break foxglove', 'bathtub wool', 'workshop girl', 'chance footnote', 'century elephant', 'alibi Guatemalan', 'fat hyena', 'clarinet rainstorm', 'care samurai', 'delivery fan', 'end cooking', 'shelf certification', 'priest sociology', 'column tomatoes', 'corn downtown', 'Santa season', 'pyjama rainstorm', 'gear explanation', 'pyramid porch', 'Afghanistan preface', 'philosophy gallon', 'spade profit', 'beat fine', 'lemonade pie', 'ikebana cushion', 'turret grey', 'clave clutch', 'soldier ghost', 'shape mother-in-law', 'weight check', 'harmonica insulation', 'curtain bathtub', 'mole snow', 'teacher sound', 'station clam', 'drain pull', 'skate fortnight', 'month drama', 'Iraq capital', 'headline brother-in-law', 'seashore bread', 'lace enemy', 'agreement English', 'donkey mirror', 'beech box', 'mice clipper', 'February tooth', 'horn subway', 'reading Greece', 'harmony almanac', 'peak wish', 'neon apology', 'vase niece', 'chill dinosaur', 'continent pheasant', 'touch software', 'copper gate', 'rise mercury', 'snowman park', 'Margaret bonsai', 'cartoon beginner', 'cent area', 'mailbox dish', 'revolver digital', 'skate disease', 'explanation vermicelli', 'emery wholesaler', 'car poison', 'asterisk viola', 'voice pizza', 'pike scent', 'gauge Edward', 'hell fir', 'move book', 'reward panda', 'drake mile', 'rutabaga dry', 'piccolo sweatshirt', 'refund kick', 'rain female', 'closet hat', 'nut paint', 'newsstand coke', 'secure court', 'cod brand', 'crown haircut', 'cod horse', 'mini-skirt wren', 'salmon microwave', 'cicada swing', 'taxi Dorothy', 'windscreen Tuesday', 'archeology sing', 'pizza day', 'wholesaler bulldozer', 'aftermath certification', 'shape snowstorm', 'curtain open', 'carnation suede', 'Iraq scissors', 'cloudy chick', 'vise diving', 'gauge back', 'stage gauge', 'bagel Ukrainian', 'fiberglass preface', 'dugout milkshake', 'lasagna attention', 'alcohol mine', 'love anthropology', 'humidity burn', 'replace parent', 'grape Thursday', 'napkin Kevin', 'cause factory', 'India sleet', 'key rose', 'bedroom precipitation', 'nurse sideboard', 'litter fiber', 'decade Aquarius', 'April mile', 'quiver star', 'Ukrainian hail', 'carrot prison', 'soup reindeer', 'asparagus engineer', 'grandson success', 'metal undershirt', 'half-brother society', 'marble structure', 'bathtub grandson', 'kayak kitchen', 'chick statement', 'crayon icebreaker', 'karate tugboat', 'law icon', 'utensil scallion', 'icon tip', 'patch cone', 'transmission pink', 'February Africa', 'lamp height', 'chin drain', 'hand step-uncle', 'system hockey', 'pendulum Aquarius', 'shake violin', 'swim shop', 'opinion broker', 'freckle sundial', 'margin balance', 'elbow novel', 'work fiber', 'bagel passive', 'trial target', 'engine peer-to-peer', 'current feather', 'attack library', 'stamp hacksaw', 'South Korea goal', 'daisy duck', 'panda radio', 'arch segment', 'island purple', 'shirt acoustic', 'pendulum larch', 'syrup icebreaker', 'sousaphone bell', 'garden river', 'withdrawal straw', 'soldier glockenspiel', 'sweatshop moustache', 'beer metal', 'creature gorilla', 'professor leaf', 'state printer', 'knot middle', 'leg pentagon', 'value freon', 'mustard judge', 'sun plier', 'postbox river', 'screwdriver bomb', 'honey watchmaker', 'tile step-grandmother', 'hall swordfish', 'size vest', 'raincoat psychology', 'cement neck', 'motion range', 'opinion bow', 'mosque nic', 'ceiling flavor', 'salesman scallion', 'geology overcoat', 'keyboard cry', 'pressure mom', 'alley buffet', 'node cord', 'Libra shake', 'doubt sidecar', 'fine blanket', 'reason shell', 'perfume scene', 'psychiatrist temperature', 'magazine blowgun', 'humidity violet', 'psychiatrist shark', 'United Kingdom island', 'aluminum mandolin', 'ornament receipt', 'lock grey', 'banjo dresser', 'statistic brand', 'kitten mistake', 'submarine cave', 'luttuce insurance', 'hand Kenneth', 'debtor arm', 'aunt green', 'drain perch', 'freighter brick', 'cry language', 'tail dresser', 'supermarket foxglove', 'character December', 'Burma eyeliner', 'destruction engine', 'army face', 'chimpanzee drum', 'story ant', 'texture sister-in-law', 'Mexico sneeze', 'fountain wholesaler', 'offer brand', 'yellow poison', 'shrimp Joseph', 'Saudi Arabia blue', 'John cheese', 'fireplace base', 'Europe law', 'ambulance community', 'grain dedication', 'paint scarf', 'aunt dinghy', 'perch zebra', 'sex quartz', 'parallelogram preface', 'bicycle deficit', 'beast offence', 'rainbow parsnip', 'restaurant goal', 'answer gray', 'William llama', 'lute grease', 'faucet prison', 'Michael lace', 'alphabet Claus', 'swallow hippopotamus', 'Nepal monkey', 'lentil size', 'forehead noodle', 'ounce mist', 'lily November', 'Japan grill', 'pencil bird', 'record carbon', 'dog reason', 'quartz starter', 'product protocol', 'course Barbara', 'jewel able', 'algebra ex-wife', 'back flame', 'octagon skill', 'interest rayon', 'cloudy industry', 'clam slice', 'oboe dredger', 'scanner aftermath', 'stove effect', 'wall lake', 'octave pantyhose', 'desk sushi', 'road policeman', 'beret sweatshirt', 'Japan hyena', 'roll back', 'low climb', 'desert screw', 'string bridge', 'herring hair', 'Sunday commission', 'dill lathe', 'court attempt', 'stamp salad', 'act monkey', 'David database', 'pedestrian texture', 'supply lunch', 'Ruth feather', 'glue bed', 'camera cub', 'meter mechanic', 'sister jeep', 'cable ptarmigan', 'power throne', 'rise doctor', 'postbox volcano', 'CD owner', 'pie whip', 'diploma girl', 'skate puppy', 'satin multimedia', 'cattle meat', 'difference blade', 'crush capital', 'cormorant hyena', 'week cormorant', 'tornado rain', 'apartment pancreas', 'banjo cent', 'bamboo lace', 'basket pea', 'dime cello', 'motorboat jogging', 'trade loss', 'cloudy receipt', 'Charles flower', 'cough tulip', 'ice mail', 'pain bottom', 'pain screwdriver', 'Carol revolver', 'great-grandmother cello', 'consonant avenue', 'belief drake', 'flower governor', 'comparison time', 'canoe seal', 'ox snowman', 'bomber sousaphone', 'temple tadpole', 'tune flesh', 'tomatoes scarf', 'helmet bumper', 'Carol ease', 'geography pantyhose', 'carp ice', 'elephant watchmaker', 'composition lier', 'year playground', 'fired cone', 'arithmetic lion', 'bank temple', 'step-sister dock', 'distribution sleet', 'border gas', 'edger sandwich', 'slip cymbal', 'cover blanket', 'sturgeon snowboarding', 'guilty cap', 'bench select', 'art underwear', 'glass mallet', 'cloudy trowel', 'caption time', 'meter good-bye', 'Morocco temperature', 'route stew', 'astronomy kilometer', 'windchime radish', 'blanket Elizabeth', 'German nerve', 'May sweater', 'sail tugboat', 'karate July', 'pilot hyacinth', 'dirt believe', 'Christmas hill', 'Barbara motorcycle', 'wind taste', 'samurai block', 'Daniel overcoat', 'hippopotamus underclothes', 'Nepal Romania', 'step-uncle boot', 'selection engine', 'blow flavor', 'cough anteater', 'amount week', 'scraper Maria', 'switch expert', 'begonia decade', 'orchestra carrot', 'heat pressure', 'chocolate halibut', 'desert saxophone', 'worm panties', 'friction disease', 'surfboard catamaran', 'politician pin', 'value margin', 'dahlia Libra', 'replace state', 'dahlia Jason', 'riddle whale', 'camel cartoon', 'Iraq disgust', 'health forest', 'plant flag', 'salary ceiling', 'rayon enemy', 'behavior attention', 'sister bakery', 'flat detective', 'odometer control', 'geese art', 'alibi building', 'fox appeal', 'interest knickers', 'timbales carnation', 'broker theater', 'sycamore insect', 'schedule blizzard', 'bed mercury', 'turnip page', 'cloth thrill', 'example meeting', 'attraction pantyhose', 'hardboard modem', 'turn stretch', 'fibre ashtray', 'puffin ikebana', 'heaven Virgo', 'stomach trapezoid', 'collision cod', 'winter college', 'shirt flood', 'Kevin bracket', 'train Ukraine', 'hen margin', 'promotion rub', 'pin jury', 'macaroni band', 'policeman backbone', 'cylinder drink', 'oven lyric', 'raft dish', 'disease vest', 'insulation vegetarian', 'woolen memory', 'report oyster', 'technician novel', 'receipt propane', 'tooth sugar', 'ant spoon', 'country Italian', 'open basketball', 'vase legal', 'step cheek', 'session beaver', 'delete hardcover', 'gym Betty', 'jail modem', 'hoe spark', 'lycra vein', 'cardboard poppy', 'America passbook', 'customer ethernet', 'ramie canoe', 'trick processing', 'Thomas tsunami', 'position whale', 'cake willow', 'system barge', 'wool stop', 'supermarket authorization', 'deal mirror', 'circle condor', 'hacksaw trombone', 'stitch security', 'clerk twilight', 'jelly Manx', 't-shirt hourglass', 'Sagittarius millisecond', 'begonia archeology', 'Richard maid', 'mouth ptarmigan', 'aftershave flugelhorn', 'trombone verdict', 'porter grip', 'copper engineer', 'oval porch', 'Greece coin', 'crown crack', 'Joseph sphere', 'key animal', 'bathtub dedication', 'seashore land', 'sturgeon morning', 'berry laundry', 'trail grandfather', 'hardboard Chinese', 'unit clock', 'swamp crop', 'hope stocking', 'environment anatomy', 'cobweb arch', 'narcissus quail', 'clock Michael', 'theory Tuesday', 'French society', 'date jar', 'mark Pakistan', 'cloth Kenneth', 'liquor bay', 'playground cylinder', 'poet commission', 'rice drizzle', 'herring lamb', 'resolution pin', 'airship glue', 'Asia rainstorm', 'button Romania', 'grandmother seed', 'crime partner', 'Abyssinian summer', 'actor weeder', 'fruit religion', 'cent purpose', 'Congo cause', 'risk insulation', 'canoe grasshopper', 'step-daughter plough', 'secretary rail', 'soybean black', 'liquor creator', 'attack January', 'bucket archaeology', 'Venezuela record', 'bottle puffin', 'propane semicircle', 'booklet footnote', 'TV cultivator', 'den quarter', 'bench literature', 'brandy breath', 'letter domain', 'snowboarding Ronald', 'advertisement squash', 'ice shelf', 'patient fisherman', 'drake ophthalmologist', 'peen reindeer', 'archaeology nurse', 'typhoon path', 'stretch author', 'grill neck', 'girl dimple', 'pint spinach', 'toothbrush pamphlet', 'alto Claus', 'blade arm', 'Greece furniture', 'quart talk', 'game cartoon', 'sex tune', 'throat intestine', 'shell lamp', 'fireplace Greek', 'spinach chimpanzee', 'cycle brush', 'woolen plow', 'margin tempo', 'William flag', 'cathedral voyage', 'gear meeting', 'partridge trouble', 'agreement undershirt', 'kick tie', 'drake farmer', 'soccer armed', 'trumpet Sphynx', 'balance mark', 'swim pamphlet', 'trade swan', 'bakery cold', 'expansion boot', 'microwave kamikaze', 'Siberian cello', 'basement decision', 'detective atomic', 'rhinoceros parrot', 'tiger beet', 'skirt stepdaughter', 'Elizabeth tiger', 'sea nickel', 'farmer pike', 'fire brand', 'grill cinema', 'tornado wholesaler', 'pyramid smile', 'middle insulation', 'condor crown', 'draw airbus', 'mascara vinyl', 'thumb farm', 'sing freon', 'kohlrabi pocket', 'gauge passive', 'cardboard wool', 'viola Robert', 'lyric journey', 'waitress plot', 'kilometer Algeria', 'space request', 'home vessel', 'middle railway', 'airport argument', 'bird Bengal', 'athlete crawdad', 'acknowledgment stretch', 'transaction touch', 'mail maid', 'slash badge', 'ladybug waste', 'secretary weather', 'kendo clerk', 'hubcap hardhat', 'Myanmar bus', 'bee step-uncle', 'Egypt income', 'innocent curtain', 'plant cream', 'format appendix', 'stitch hydrant', 'grasshopper control', 'sing donkey', 'millisecond drizzle', 'shears drama', 'dragonfly bedroom', 'periodical education', 'sturgeon friend', 'feast archeology', 'crow manicure', 'golf exchange', 'spinach bee', 'respect age', 'stock daughter', 'opinion fibre', 'cave copy', 'rock place', 'cobweb soldier', 'eel napkin', 'flesh index', 'attic structure', 'Cuban breath', 'sundial lift', 'Syria gun', 'switch lunchroom', 'spinach area', 'relish fighter', 'Sharon March', 'activity monkey', 'swordfish basin', 'fir math', 'bucket phone', 'pump Daniel', 'great-grandfather fold', 'confirmation mini-skirt', 'bandana cold', 'open landmine', 'rub boundary', 'scraper coffee', 'great-grandmother death', 'football engine', 'wash birth', 'train evening', 'justice almanac', 'chord calf', 'clarinet print', 'kitty blood', 'deposit Bangladesh', 'low wholesaler', 'stick pest', 'gold straw', 'rat bass', 'bassoon servant', 'office cheese', 'orange appliance', 'text rayon', 'believe creature', 'drawbridge knight', 'latency step-grandfather', 'softdrink lyric', 'hallway forehead', 'beer text', 'rectangle South Korea', 'rate caterpillar', 'fifth bread', 'math ink', 'cheque burn', 'battery continent', 'sea queen', 'diving health', 'Christopher whistle', 'look store', 'lead prose', 'cork difference', 'salt Margaret', 'accordion Margaret', 'spandex agenda', 'May fragrance', 'roll tent', 'relatives separated', 'watchmaker Philippines', 'yogurt veil', 'semicolon fedelini', 'drug consonant', 'car question', 'work poultry', 'linen format', 'good-bye guide', 'ticket cultivator', 'radar port', 'cowbell Indonesia', 'spark minute', 'writer raincoat', 'industry ant', 'measure Sphynx', 'chest cardigan', 'cabbage bead', 'tree oatmeal', 'textbook mom', 'Joseph geology', 'bite crib', 'pediatrician hyena', 'correspondent spring', 'scallion light', 'part bakery', 'feeling hat', 'Donna Kevin', 'brake link', 'mark equipment', 'comfort screw', 'turnover Friday', 'gas eagle', 'comics luttuce', 'gateway community', 'jute neon', 'screwdriver square', 'hurricane pipe', 'sweatshop spaghetti', 'trade company', 'turret grade', 'form college', 'riverbed kitchen', 'pimple stepmother', 'message Peru', 'water turtle', 'prepared bass', 'notebook fireplace', 'party inventory', 'print airship', 'crocus promotion', 'cell duckling', 'success thought', 'duckling court', 'epoxy cyclone', 'buzzard thread', 'product panther', 'Romanian Betty', 'January patient', 'arch fiberglass', 'harmonica position', 'secretary William', 'nic baboon', 'Donald panties', 'driving Edward', 'pantry emery', 'rake produce', 'gear anatomy', 'invention postage', 'kilogram bobcat', 'eyebrow crowd', 'bookcase watchmaker', 'grape mall', 'swimming hot', 'wave business', 'fly sense', 'wasp nest', 'straw washer', 'shrine report', 'sister-in-law fountain', 'trombone carpenter', 'mercury fireman', 'sidewalk kiss', 'waitress polish', 'basket cave', 'snail novel', 'comparison melody', 'drain network', 'revolve work', 'giraffe stamp', 'newsstand development', 'roast brown', 'port needle', 'column fact', 'spaghetti debt', 'purple stepdaughter', 'eel decrease', 'ton reduction', 'earth archeology', 'authorization teacher', 'mask red', 'process streetcar', 'Swiss cabinet', 'craftsman quill', 'unit difference', 'nylon trowel', 'helicopter maid', 'South Africa creditor', 'certification select', 'bankbook herring', 'barber radiator', 'sprout pail', 'afternoon school', 'plier fighter', 'nut skate', 'clerk segment', 'deer caution', 'harmonica purple', 'boundary stream', 'oyster quart', 'shears Richard', 'country kayak', 'plain knife', 'court eight', 'gauge Syria', 'facilities bush', 'waiter poultry', 'resolution beach', 'sink snowman', 'session wallaby', 'diving brace', 'gray quilt', 'Iran observation', 'boat dryer', 'aftermath galley', 'motorboat twine', 'rubber latex', 'chess underpants', 'United Kingdom step-mother', 'bike Thursday', 'meal restaurant', 'date temperature', 'menu jaguar', 'cold psychiatrist', 'trousers kettle', 'copyright tadpole', 'Nancy decade', 'Thailand whiskey', 'pull kite', 'rat switch', 'interactive grenade', 'doll break', 'chive windscreen', 'sausage baritone', 'rise tie', 'piano sponge', 'rotate velvet', 'step-aunt porch', 'blow ball', 'damage Uzbekistan', 'hat sushi', 'system architecture', 'crack grain', 'exchange wasp', 'dolphin pimple', 'fired debtor', 'textbook condor', 'algebra wrecker', 'colt creature', 'stomach farmer', 'shorts pancreas', 'wave scarf', 'conga lilac', 'voice albatross', 'profit resolution', 'salt ophthalmologist', 'watchmaker twist', 'syrup border', 'birch drop', 'hall science', 'cereal repair', 'budget drum', 'utensil chain', 'flood odometer', 'velvet medicine', 'creditor digestion', 'place port', 'fox sponge', 'blowgun trousers', 'Balinese meteorology', 'mouth team', 'spoon sweatshop', 'men tuna'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosined_products = list(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of the comparative weights for multiple item purchase history\n",
    "* An issue to take into account with the item to item collaborative filtering is whether or not to average out the cosine similarities or to take each individual items similar products and just recommend the highest scores to the customers previous purchases\n",
    "* In this case, I have chosen to recommend the highest scores for each product and not average the scores because it makes more sense to me that a customer would want the most similar to each of the products they have purchased, not something in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_weights(prod_set, prod_dict = data):\n",
    "    \"\"\"\n",
    "       Takes products and returns a dictionary with the highest similarity scores of those \n",
    "       products for each of the entire set of products\n",
    "       \n",
    "       Parameters:\n",
    "       *args\n",
    "         products in string format\n",
    "      \n",
    "       Returns:\n",
    "       dictionary\n",
    "         a dictionary of the highest similarity scores for each product \n",
    "        \"\"\"\n",
    "    weights = prod_dict[list(prod_set)[0]]\n",
    "    for prod in list(prod_set):\n",
    "        for k,v in weights.items(): \n",
    "            if prod_dict[prod][k] > v:\n",
    "                weights[k] = prod_dict[prod][k]\n",
    "            else:\n",
    "                weights[k] = v\n",
    "    return weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_weights(cust_prods['Betty Nestor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of the recommendatons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_prods(prod_set, n_recs = 5):\n",
    "    \"\"\"\n",
    "    Return top five recommended products\n",
    "    based on the products in the customers previous purchases.\n",
    "    \n",
    "    Parameters:\n",
    "    prod_set\n",
    "      set of products the customer has previously purchased of any length\n",
    "    prod_dict\n",
    "      dictionary of all products with their cosine similarities to all other products\n",
    "    n_recs\n",
    "      integer describing number or recommendations required\n",
    "      \n",
    "    Return\n",
    "      set of recommended products\n",
    "    \n",
    "    \"\"\"\n",
    "    #pulling out the max weights of each product against this set\n",
    "    weights = combine_weights(prod_set)\n",
    "\n",
    "\n",
    "    #sorting the weighted dictionary by the weight    \n",
    "    sorted_w = sorted(weights.items(), key=lambda kv: kv[1], reverse=True) \n",
    "\n",
    "\n",
    "    #creation of a set so the same product doesn't get added multiple times\n",
    "    \n",
    "    unique_prods = set()\n",
    "    list_prods = []\n",
    "    \n",
    "    #iterating through sorted weights to create a set of 5 unique products\n",
    "    for i in sorted_w:\n",
    "        if round(i[1],5) == 1:\n",
    "            pass\n",
    "        else:\n",
    "            if len(unique_prods) == n_recs:\n",
    "                break\n",
    "            elif i in prod_set:\n",
    "                pass\n",
    "            else:\n",
    "                unique_prods.add(i[0])\n",
    "                list_prods.append(i[0])\n",
    "                                       \n",
    "    return list_prods\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_products = recommend_for_prods({'grip decade', 'back cowbell', 'aunt leg','January physician','limit Lisa'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'French jewel',\n",
       " 'January physician',\n",
       " 'cell basketball',\n",
       " 'hyena peer-to-peer',\n",
       " 'touch panty'}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_for_prods(cust_prods['Betty Nestor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creation of dictionary containing all the customers and the products they have previously purchased so that a customers name can be called if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_prods = {}\n",
    "for cust, prod in prod_sales:\n",
    "    cust_prods.setdefault(cust, set()).add(prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up network data for this model\n",
    " For a network model you need to provide the information of nodes (each of the products represented as a point) and the edges (the connections between them, in this case, the cusomers who have purchased both items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = df.loc[df['product_name'].isin(cosined_products)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33681, 32)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_edge = 'customer_name'\n",
    "column_ID = 'product_name'\n",
    "\n",
    "# select columns, remove NaN\n",
    "data_to_merge = products_df[[column_ID, column_edge]].dropna(subset=[column_edge]).drop_duplicates() \n",
    "\n",
    "# To create connections between products who have been purchased by the same person,\n",
    "# join data with itself on the 'ID' column.\n",
    "data_to_merge = data_to_merge.merge(\n",
    "    data_to_merge[[column_ID, column_edge]].rename(columns={column_ID:column_ID+\"_2\"}), \n",
    "    on=column_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>product_name_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>limit Lisa</td>\n",
       "      <td>Rodrigo Keefe</td>\n",
       "      <td>limit Lisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>limit Lisa</td>\n",
       "      <td>Julianna Queen</td>\n",
       "      <td>limit Lisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>limit Lisa</td>\n",
       "      <td>Palmer Bankston</td>\n",
       "      <td>limit Lisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>limit Lisa</td>\n",
       "      <td>Lupe Pettigrew</td>\n",
       "      <td>limit Lisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>limit Lisa</td>\n",
       "      <td>Genaro Cheatham</td>\n",
       "      <td>limit Lisa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_name    customer_name product_name_2\n",
       "0   limit Lisa    Rodrigo Keefe     limit Lisa\n",
       "1   limit Lisa   Julianna Queen     limit Lisa\n",
       "2   limit Lisa  Palmer Bankston     limit Lisa\n",
       "3   limit Lisa   Lupe Pettigrew     limit Lisa\n",
       "4   limit Lisa  Genaro Cheatham     limit Lisa"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By joining the data with itself, products will have a connection with themselves.\n",
    "# Remove self connections, to keep only connected products which are different.\n",
    "d = data_to_merge[~(data_to_merge[column_ID]==data_to_merge[column_ID+\"_2\"])] \\\n",
    "    .dropna()[[column_ID, column_ID+\"_2\", column_edge]]\n",
    "    \n",
    "# To avoid counting twice the connections (product 1 connected to product 2 and product 2 connected to product 1)\n",
    "# we force the first ID to be \"lower\" then ID_2\n",
    "d.drop(d.loc[d[column_ID+\"_2\"]<d[column_ID]].index.tolist(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_name_2</th>\n",
       "      <th>customer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>aunt leg</td>\n",
       "      <td>limit Lisa</td>\n",
       "      <td>Betty Nestor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>January physician</td>\n",
       "      <td>aunt leg</td>\n",
       "      <td>Chris Baldwin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>cafe advertisement</td>\n",
       "      <td>grip decade</td>\n",
       "      <td>Joni Bennett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>cafe advertisement</td>\n",
       "      <td>grip decade</td>\n",
       "      <td>Jerry Mccarty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>back cowbell</td>\n",
       "      <td>grip decade</td>\n",
       "      <td>Nina Cooper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product_name product_name_2  customer_name\n",
       "9             aunt leg     limit Lisa   Betty Nestor\n",
       "20   January physician       aunt leg  Chris Baldwin\n",
       "46  cafe advertisement    grip decade   Joni Bennett\n",
       "53  cafe advertisement    grip decade  Jerry Mccarty\n",
       "84        back cowbell    grip decade    Nina Cooper"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "flourish_edges = d.groupby([column_ID, column_ID+'_2'])[column_edge].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_name_2</th>\n",
       "      <th>customer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>America passbook</td>\n",
       "      <td>button Romania</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>America passbook</td>\n",
       "      <td>deposit Bangladesh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Barbara motorcycle</td>\n",
       "      <td>cattle meat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CD owner</td>\n",
       "      <td>scraper Maria</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Carol ease</td>\n",
       "      <td>alley buffet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         product_name      product_name_2  customer_name\n",
       "0    America passbook      button Romania              1\n",
       "1    America passbook  deposit Bangladesh              1\n",
       "2  Barbara motorcycle         cattle meat              1\n",
       "3            CD owner       scraper Maria              1\n",
       "4          Carol ease        alley buffet              1"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flourish_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389, 3)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flourish_edges.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I only want to graph the products that are connected to others as an example of the connections. Otherwise, I will have too many products in my graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_list = flourish_edges['product_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_list.extend(flourish_edges['product_name_2'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_list = list(dict.fromkeys(nodes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "flourish_edges.to_csv(r'./datasets/network_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "flourish_nodes = df[df['product_name'].isin(nodes_list)][['product_name','category','brand_name','price']]\\\n",
    "                                             .drop_duplicates(subset=['product_name'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393, 4)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flourish_nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "flourish_nodes.to_csv(r'./datasets/network_nodes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trialling pieces of code for my web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_1 = str('grip decade')\n",
    "product_2 = str('')\n",
    "product_3 = str('aunt leg')\n",
    "product_4 = str()\n",
    "product_5 = str('limit Lisa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = {product_1,product_2,product_3,product_4,product_5}\n",
    "products = set()\n",
    "for n in product:\n",
    "    if n != '':\n",
    "        products.add(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aunt leg', 'grip decade', 'limit Lisa'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = {'grip decade', 'back cowbell', 'aunt leg','January physician','limit Lisa'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_for_prods(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recs = {}\n",
    "for n in range(1, (len(rec_products)+1)):\n",
    "        final_recs['rec_prod_'+str(n)] = rec_products[n-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collating images for each of the products I will use in the app demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = {'karate tugboat'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['margin balance', 'deal mirror', 'fan draw', 'mayonnaise mom', 'text Italy']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_for_prods(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_images = {'broker ethernet':\"http://wiznetmuseum.com/wp/wp-content/uploads/2018/03/106-300x183.jpg\",\n",
    "          'baseball step-grandmother':\"https://i.etsystatic.com/14835601/r/il/f8cb7e/2054134143/il_794xN.2054134143_htjh.jpg\",\n",
    "          'delivery order':\"https://www.dinnerfactory.ca/wp-content/uploads/2018/07/dinner-factory-delivery.png\",\n",
    "          'epoch bat':\"https://www.clipartwiki.com/clipimg/detail/11-113504_cute-bat-clipart-cute-bat-clipart-png.png\",\n",
    "          'cafe advertisement': \"https://cdn.atulhost.com/wp-content/uploads/2017/10/advertise-cafe-facebook.jpg\",\n",
    "          'duckling court': \"https://i.kinja-img.com/gawker-media/image/upload/s--5OWqTQeR--/c_scale,f_auto,fl_progressive,q_80,w_800/dk1kxw5lrjpdx4alhjud.jpg\",\n",
    "          'grip decade': \"https://cdn.shopify.com/s/files/1/0095/7552/products/mcc-new-decade-7colors_grande.jpg?v=1534546352\",\n",
    "          'back cowbell': \"https://i.pinimg.com/originals/13/8d/fa/138dfaf91ad2694eab65e8c89253bb19.jpg\",\n",
    "          'aunt leg': \"https://ctl.s6img.com/society6/img/qR5kUo42dezjcO774h570hlyQxY/w_700/leggings/medium/front/~artwork,fw_7503,fh_9001,fx_-274,fy_-1300,iw_9000,ih_9000/s6-original-art-uploads/society6/uploads/misc/39bf0cb86f994ff18a88dfacc5b5b752/~~/aunt-smiling-leggings.jpg\",\n",
    "          'limit Lisa' : \"https://media1.popsugar-assets.com/files/thumbor/IAIBqKwqZX4M8aIImjr2hu9KR4Y/fit-in/2048xorig/filters:format_auto-!!-:strip_icc-!!-/2018/12/10/940/n/1922283/1c694d4c5c0edbcdf0bee0.07759189_lisa_simpson_pin/i/Lisa-Simpson-Pin.jpg\",\n",
    "          'nerve motorboat': \"https://www.flemingyachts.com/photos/yachts/large/711.jpg\",\n",
    "          'motion cave': \"https://s.abcnews.com/images/Health/180709_vod_orig_cavedisease_hpMain_16x9_992.jpg\",\n",
    "          'sphere room': \"https://i.pinimg.com/736x/1b/5e/b7/1b5eb76969c882fcd9981f64ea36addd--pinterest-account.jpg\",\n",
    "          'offer ear': \"https://fiverr-res.cloudinary.com/images/t_main1,q_auto,f_auto/gigs/110627907/original/6f346bcbc8cb84a777719e392438483d13ddbc7a/lend-a-listening-ear-and-offer-advice-if-there-is-a-need.png\",\n",
    "          'picture toad': \"https://www.abc.net.au/news/image/131608-3x2-700x467.jpg\",\n",
    "          'January physician': \"https://www.myhaliburtonnow.com/wp-content/uploads/2016/02/doctor-health-wellness.jpg\",\n",
    "          'rayon enemy': \"https://shop.r10s.jp/palm-nut/cabinet/04917692/06046630/imgrc0074368302.jpg\",\n",
    "          'comparison Mexico': \"https://i.redd.it/1ywm6fflfpq21.jpg\",\n",
    "          'Kenneth pipe': \"http://credo.library.umass.edu/images/resize/600x600/mums887-s03-f19-i001-001.jpg\",\n",
    "          'margin balance': \"https://www.itaubba-economia.com/cdn/uf/images/Imagem4(610).png\",\n",
    "          'router cup': \"http://www.thecivilian.co.nz/wp-content/uploads/2019/08/elderlyrugbyfeature-300x205.jpg\",\n",
    "          'Norwegian tomatoes': \"https://image.sciencenorway.no/1554342.jpg?imageId=1554342&width=353&height=265\",\n",
    "          'William llama': \"https://www.yellowstonesafari.com/modules/mod_btimagegallery/images/original/536fbf0469ea8777708cbd6b2c4a465b.jpg\",\n",
    "          'eggnog bathtub': \"https://activerain.com/image_store/uploads/4/3/7/5/8/ar122998894885734.jpg\",\n",
    "          'bicycle particle': \"https://media.istockphoto.com/vectors/cyclist-rides-a-bicycle-particle-divergent-silhouette-vector-id825171206\",\n",
    "          'deal mirror': \"https://assets.loaf.com/images/product_800/2282480-real-deal-brass-round-mirror.jpg\",\n",
    "          'fan draw': \"https://www.miyaguikenbrasil.com/upload/2019/03/07/table-fan-drawing-architectural-drawings-of-ceiling-fans-l-f14f7442658f9edb.png\",\n",
    "          'mayonnaise mom': \"https://cdn10.phillymag.com/wp-content/uploads/sites/3/2018/08/mayonnaise-industry-millennials.jpg\",\n",
    "          'text Italy': \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/01/Banner_of_Giovine_Italia.png/200px-Banner_of_Giovine_Italia.png\",\n",
    "          'feeling biology': \"https://cdn.the-scientist.com/assets/articleNo/32941/iImg/7018/afab1467-56c2-4623-8e75-b1ba1d274129-feature21.jpg\",\n",
    "          'spring invoice': \"https://i.ebayimg.com/images/g/JGkAAOSwHhRb5gRm/s-l1600.jpg\",\n",
    "          'thunder random': \"http://www.dumpaday.com/wp-content/uploads/2018/03/photos-14-10.jpg\",\n",
    "          'tuna swordfish': \"https://caperfrasers.files.wordpress.com/2010/08/tuna1.jpg\",\n",
    "          'pajama dinner': \"http://4.bp.blogspot.com/-WAd2LtjVuHw/TvU6O2Fp3HI/AAAAAAAAEko/9na37ZrpfKA/s400/IMG_1992.JPG\",\n",
    "          'pink poet': \"https://cdn.shopify.com/s/files/1/2376/4853/products/c.jpg?v=1556234864\",\n",
    "          'rule kayak':\"https://i2.wp.com/www.paddlinglight.com/pl/wp-content/uploads/2016/08/hansel_bryan_051016-215.jpg?w=960&ssl=1\",\n",
    "          'ball authorization': \"https://tshop.r10s.jp/matsucame/cabinet/sam/tsu6322-sam.jpg?fitin=330:330\",\n",
    "          'barge Siamese': \"https://grangerprints.printstoreonline.com/image/497/7499435/7499435_600_450_676_0_fit_0_66f9b956dc0363e92e291fffb02b4f3e.jpg\",\n",
    "          'wallaby pig': \"https://external-preview.redd.it/O0mqZ57Fwe_iuWBkNF4YVl0n9L6kZyLYdmeL0pTNMZw.jpg?auto=webp&s=ce0bc6723e5da4815ed5c2088e5b09807bf63321\",\n",
    "          'root badge': \"https://cdn.shopify.com/s/files/1/1545/2923/products/root-red-logo-badge-161207_500x.jpg?v=1481150915\",\n",
    "          'samurai brow': \"https://cdn.asiatatler.com/asiatatler/i/hk/2018/11/06204003-story-image-10262_cover_1000x616.jpg\",\n",
    "          'creditor hour':\"https://www.experian.com/blogs/insights/wp-content/uploads/2018/03/Blog-credit-freeze-930x420.jpg\",\n",
    "          'karate tugboat': \"https://m.media-amazon.com/images/M/MV5BMDI2NWQxOGUtNWM5Yi00YjE5LTg2ZjctOThmM2Y0NDAwNGVkXkEyXkFqcGdeQXVyMjM1ODU5MDU@._V1_UY268_CR43,0,182,268_AL_.jpg\",\n",
    "          'stocking insulation': \"http://www.ybsinsulation.com/wp-content/uploads/2017/07/brands2-244x300.jpg\",\n",
    "          'hyena peer-to-peer': \"https://www.pbs.org/wgbh/nova/media/images/Coalition_photo_credit_Kate_Yoshida_kIuFHhE.width-1500.jpg\",\n",
    "          'French jewel': \"https://1.bp.blogspot.com/-sKPFZItIuh4/W7ulkokNCLI/AAAAAAAAwI4/x1XsCFHAmEU5axwEUl2F2FEaJQMQokc_gCLcBGAs/s320/hopediamond.jpg\",\n",
    "          'question match': \"https://miro.medium.com/max/800/1*Km98PgzRp9yRYfVZeSzwzQ.png\",\n",
    "          'desert vest': \"https://www.varusteleka.com/pictures/thumbs500a/6149.jpg\",\n",
    "          'stitch cause': \"https://cdn.hswstatic.com/gif/treat-side-stitch-2.jpg\",\n",
    "          'view reaction': \"https://cdn.shopify.com/s/files/1/0065/4917/6438/products/a-scientist-creating-a-chemical-reaction-and-a-view-of-the-city-from-a-top-of-a-building-during-the-day-background_740x.jpg?v=1544771614\",\n",
    "          'law icon': \"https://image.freepik.com/free-vector/background-with-advocacy-elements_23-2147802094.jpg\",\n",
    "          'teaching softdrink':\"https://i0.wp.com/happyhomefairy.com/wp-content/uploads/2012/04/soda-11.jpg?resize=392%2C666&ssl=1\",\n",
    "          'Nancy mistake':\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1174333611l/382090.jpg\",\n",
    "          'weapon pigeon': \"https://futureforce.navylive.dodlive.mil/files/2015/01/Project-Pigeon-Web.jpg\",\n",
    "          'tree oatmeal': \"https://media.istockphoto.com/photos/oatmeal-in-the-bowl-and-ears-of-oats-on-a-piece-of-bark-tree-picture-id856898374\",\n",
    "          'expansion boot': \"https://images-na.ssl-images-amazon.com/images/I/61YP743Nv3L._AC_UY675_.jpg\",\n",
    "          'advertisement squash': \"https://d3nuqriibqh3vw.cloudfront.net/styles/aotw_card_ir/s3/baxters_bof_press_251115_3_aotw_0.jpg?itok=o1o8EG7p\",\n",
    "          'vein minibus': \"https://assets.newatlas.com/dims4/default/66909f0/2147483647/strip/true/crop/1440x961+0+60/resize/1160x774!/quality/90/?url=https%3A%2F%2Fassets.newatlas.com%2Farchive%2Fsuzuki-air-triser-5.jpg\",\n",
    "          'acrylic television': \"https://p.globalsources.com/IMAGES/PDT/B1163660980/Acrylic-TV-stand.jpg\"}\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://wiznetmuseum.com/wp/wp-content/uploads/2018/03/106-300x183.jpg'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_images['broker ethernet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/prod_images.json', 'w') as fp:\n",
    "    json.dump(prod_images, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trial of code for showing no image if an image is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recs = []\n",
    "for prod in recommend_for_prods(hello):\n",
    "    attr = {}\n",
    "    attr['name'] = prod\n",
    "    try:\n",
    "        attr['image'] = images[prod]\n",
    "    except:\n",
    "        attr['image'] = \"\"\n",
    "    final_recs.append(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'baseball step-grandmother',\n",
       "  'image': 'https://i.etsystatic.com/14835601/r/il/f8cb7e/2054134143/il_794xN.2054134143_htjh.jpg'},\n",
       " {'name': 'delivery order',\n",
       "  'image': 'https://www.dinnerfactory.ca/wp-content/uploads/2018/07/dinner-factory-delivery.png'},\n",
       " {'name': 'epoch bat',\n",
       "  'image': 'https://www.clipartwiki.com/clipimg/detail/11-113504_cute-bat-clipart-cute-bat-clipart-png.png'},\n",
       " {'name': 'cafe advertisement',\n",
       "  'image': 'https://cdn.atulhost.com/wp-content/uploads/2017/10/advertise-cafe-facebook.jpg'},\n",
       " {'name': 'duckling court', 'image': ''}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting dictionary into two so that the file size is small enough for my app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_cosine_1 = {key: value for i, (key, value) in enumerate(prod_cosine.items()) if i % 2 == 0}\n",
    "prod_cosine_2 = {key: value for i, (key, value) in enumerate(prod_cosine.items()) if i % 2 == 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prod_cosine_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prod_cosine_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/prod_cosine_1.json', 'w') as fp:\n",
    "    json.dump(prod_cosine_1, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/prod_cosine_2.json', 'w') as fp:\n",
    "    json.dump(prod_cosine_2, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now I want to compress the json files to further reduce their size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import zlib\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/prod_cosine_1.json', 'rb') as f_in:\n",
    "    with gzip.open('./web_application/datasets/prod_cosine_1.json.gz', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('./web_application/datasets/prod_cosine_1.json.gz', 'rb') as fp:\n",
    "    json_bytes = fp.read()\n",
    "nope = json.loads(json_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['limit Lisa', 'aunt leg', 'apple lentil', 'cafe advertisement', 'segment ocean', 'January physician', 'back cowbell', 'rose Abyssinian', 'battery letter', 'idea meteorology', 'Brian Sagittarius', 'agreement pentagon', 'metal lyric', 'sturgeon environment', 'conifer exchange', 'raven neck', 'top battery', 'basement orchestra', 'volcano Europe', 'orchid thing', 'patch thrill', 'beautician patch', 'gondola hook', 'beet meter', 'pancreas anger', 'porch butcher', 'epoxy interest', 'kitchen copyright', 'cycle lawyer', 'ophthalmologist debt', 'interest salesman', 'bag Libra', 'face begonia', 'coast semicolon', 'Linda match', 'comfort degree', 'fir police', 'burn knife', 'sack Iraq', 'ounce train', 'John Cancer', 'pest care', 'grey time', 'hardcover saw', 'hyena cabinet', 'armed story', 'north soup', 'John pie', 'flame Thomas', 'alligator fish', 'Pisces colony', 'orchid equipment', 'moat Jason', 'seeder defense', 'smile math', 'cause point', 'memory John', 'skate David', 'son peak', 'refund boat', 'alligator columnist', 'drop religion', 'base desire', 'drive distributor', 'word difference', 'song Christopher', 'top workshop', 'quiet sundial', 'Fahrenheit swamp', 'lawyer distribution', 'bee arrow', 'north supermarket', 'colt coat', 'hamburger handicap', 'museum join', 'smile sampan', 'scale slice', 'Kevin stem', 'control processing', 'fork faucet', 'study father', 'note pot', 'scarecrow statement', 'time apple', 'bathtub wool', 'chance footnote', 'alibi Guatemalan', 'clarinet rainstorm', 'delivery fan', 'shelf certification', 'column tomatoes', 'Santa season', 'gear explanation', 'Afghanistan preface', 'spade profit', 'lemonade pie', 'turret grey', 'soldier ghost', 'weight check', 'curtain bathtub', 'teacher sound', 'drain pull', 'month drama', 'headline brother-in-law', 'lace enemy', 'donkey mirror', 'mice clipper', 'horn subway', 'harmony almanac', 'neon apology', 'chill dinosaur', 'touch software', 'rise mercury', 'Margaret bonsai', 'cent area', 'revolver digital', 'explanation vermicelli', 'car poison', 'voice pizza', 'gauge Edward', 'move book', 'drake mile', 'piccolo sweatshirt', 'rain female', 'nut paint', 'secure court', 'crown haircut', 'mini-skirt wren', 'cicada swing', 'windscreen Tuesday', 'pizza day', 'aftermath certification', 'curtain open', 'Iraq scissors', 'vise diving', 'stage gauge', 'fiberglass preface', 'lasagna attention', 'love anthropology', 'replace parent', 'napkin Kevin', 'India sleet', 'bedroom precipitation', 'litter fiber', 'April mile', 'Ukrainian hail', 'soup reindeer', 'grandson success', 'half-brother society', 'bathtub grandson', 'chick statement', 'karate tugboat', 'utensil scallion', 'patch cone', 'February Africa', 'chin drain', 'system hockey', 'shake violin', 'opinion broker', 'margin balance', 'work fiber', 'trial target', 'current feather', 'stamp hacksaw', 'daisy duck', 'arch segment', 'shirt acoustic', 'syrup icebreaker', 'garden river', 'soldier glockenspiel', 'beer metal', 'professor leaf', 'knot middle', 'value freon', 'sun plier', 'screwdriver bomb', 'tile step-grandmother', 'size vest', 'cement neck', 'opinion bow', 'ceiling flavor', 'geology overcoat', 'pressure mom', 'node cord', 'doubt sidecar', 'reason shell', 'psychiatrist temperature', 'humidity violet', 'United Kingdom island', 'ornament receipt', 'banjo dresser', 'kitten mistake', 'luttuce insurance', 'debtor arm', 'drain perch', 'cry language', 'supermarket foxglove', 'Burma eyeliner', 'army face', 'story ant', 'Mexico sneeze', 'offer brand', 'shrimp Joseph', 'John cheese', 'Europe law', 'grain dedication', 'aunt dinghy', 'sex quartz', 'bicycle deficit', 'rainbow parsnip', 'answer gray', 'lute grease', 'Michael lace', 'swallow hippopotamus', 'lentil size', 'ounce mist', 'Japan grill', 'record carbon', 'quartz starter', 'course Barbara', 'algebra ex-wife', 'octagon skill', 'cloudy industry', 'oboe dredger', 'stove effect', 'octave pantyhose', 'road policeman', 'Japan hyena', 'low climb', 'string bridge', 'Sunday commission', 'court attempt', 'act monkey', 'pedestrian texture', 'Ruth feather', 'camera cub', 'sister jeep', 'power throne', 'postbox volcano', 'pie whip', 'skate puppy', 'cattle meat', 'crush capital', 'week cormorant', 'apartment pancreas', 'bamboo lace', 'dime cello', 'trade loss', 'Charles flower', 'ice mail', 'pain screwdriver', 'great-grandmother cello', 'belief drake', 'comparison time', 'ox snowman', 'temple tadpole', 'tomatoes scarf', 'Carol ease', 'carp ice', 'composition lier', 'fired cone', 'bank temple', 'distribution sleet', 'edger sandwich', 'cover blanket', 'guilty cap', 'art underwear', 'cloudy trowel', 'meter good-bye', 'route stew', 'windchime radish', 'German nerve', 'sail tugboat', 'pilot hyacinth', 'Christmas hill', 'wind taste', 'Daniel overcoat', 'Nepal Romania', 'selection engine', 'cough anteater', 'scraper Maria', 'begonia decade', 'heat pressure', 'desert saxophone', 'friction disease', 'politician pin', 'dahlia Libra', 'dahlia Jason', 'camel cartoon', 'health forest', 'salary ceiling', 'behavior attention', 'flat detective', 'geese art', 'fox appeal', 'timbales carnation', 'sycamore insect', 'bed mercury', 'cloth thrill', 'attraction pantyhose', 'turn stretch', 'puffin ikebana', 'stomach trapezoid', 'winter college', 'Kevin bracket', 'hen margin', 'pin jury', 'policeman backbone', 'oven lyric', 'disease vest', 'woolen memory', 'technician novel', 'tooth sugar', 'country Italian', 'vase legal', 'session beaver', 'gym Betty', 'hoe spark', 'cardboard poppy', 'customer ethernet', 'trick processing', 'position whale', 'system barge', 'supermarket authorization', 'circle condor', 'stitch security', 'jelly Manx', 'Sagittarius millisecond', 'Richard maid', 'aftershave flugelhorn', 'porter grip', 'oval porch', 'crown crack', 'key animal', 'seashore land', 'berry laundry', 'hardboard Chinese', 'swamp crop', 'environment anatomy', 'narcissus quail', 'theory Tuesday', 'date jar', 'cloth Kenneth', 'playground cylinder', 'rice drizzle', 'resolution pin', 'Asia rainstorm', 'grandmother seed', 'Abyssinian summer', 'fruit religion', 'Congo cause', 'canoe grasshopper', 'secretary rail', 'liquor creator', 'bucket archaeology', 'bottle puffin', 'booklet footnote', 'den quarter', 'brandy breath', 'snowboarding Ronald', 'ice shelf', 'drake ophthalmologist', 'archaeology nurse', 'stretch author', 'girl dimple', 'toothbrush pamphlet', 'blade arm', 'quart talk', 'sex tune', 'shell lamp', 'spinach chimpanzee', 'woolen plow', 'William flag', 'gear meeting', 'agreement undershirt', 'drake farmer', 'trumpet Sphynx', 'swim pamphlet', 'bakery cold', 'microwave kamikaze', 'basement decision', 'rhinoceros parrot', 'skirt stepdaughter', 'sea nickel', 'fire brand', 'tornado wholesaler', 'middle insulation', 'draw airbus', 'thumb farm', 'kohlrabi pocket', 'cardboard wool', 'lyric journey', 'kilometer Algeria', 'home vessel', 'airport argument', 'athlete crawdad', 'transaction touch', 'slash badge', 'secretary weather', 'hubcap hardhat', 'bee step-uncle', 'innocent curtain', 'format appendix', 'grasshopper control', 'millisecond drizzle', 'dragonfly bedroom', 'sturgeon friend', 'crow manicure', 'spinach bee', 'stock daughter', 'cave copy', 'cobweb soldier', 'flesh index', 'Cuban breath', 'Syria gun', 'spinach area', 'Sharon March', 'swordfish basin', 'bucket phone', 'great-grandfather fold', 'bandana cold', 'rub boundary', 'great-grandmother death', 'wash birth', 'justice almanac', 'clarinet print', 'deposit Bangladesh', 'stick pest', 'rat bass', 'office cheese', 'text rayon', 'drawbridge knight', 'softdrink lyric', 'beer text', 'rate caterpillar', 'math ink', 'battery continent', 'diving health', 'look store', 'cork difference', 'accordion Margaret', 'May fragrance', 'relatives separated', 'yogurt veil', 'drug consonant', 'work poultry', 'good-bye guide', 'radar port', 'spark minute', 'industry ant', 'chest cardigan', 'tree oatmeal', 'Joseph geology', 'pediatrician hyena', 'scallion light', 'feeling hat', 'brake link', 'comfort screw', 'gas eagle', 'gateway community', 'screwdriver square', 'sweatshop spaghetti', 'turret grade', 'riverbed kitchen', 'message Peru', 'prepared bass', 'party inventory', 'crocus promotion', 'success thought', 'epoxy cyclone', 'product panther', 'January patient', 'harmonica position', 'nic baboon', 'driving Edward', 'rake produce', 'invention postage', 'eyebrow crowd', 'grape mall', 'wave business', 'wasp nest', 'shrine report', 'trombone carpenter', 'sidewalk kiss', 'basket cave', 'comparison melody', 'revolve work', 'newsstand development', 'port needle', 'spaghetti debt', 'eel decrease', 'earth archeology', 'mask red', 'Swiss cabinet', 'unit difference', 'helicopter maid', 'certification select', 'barber radiator', 'afternoon school', 'nut skate', 'deer caution', 'boundary stream', 'shears Richard', 'plain knife', 'gauge Syria', 'waiter poultry', 'sink snowman', 'diving brace', 'Iran observation', 'aftermath galley', 'rubber latex', 'United Kingdom step-mother', 'meal restaurant', 'menu jaguar', 'trousers kettle', 'Nancy decade', 'pull kite', 'interactive grenade', 'chive windscreen', 'rise tie', 'rotate velvet', 'blow ball', 'hat sushi', 'crack grain', 'dolphin pimple', 'textbook condor', 'colt creature', 'shorts pancreas', 'conga lilac', 'profit resolution', 'watchmaker twist', 'birch drop', 'cereal repair', 'utensil chain', 'velvet medicine', 'place port', 'blowgun trousers', 'mouth team', 'men tuna'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nope.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### and check the new loading code will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = {}\n",
    "for n in range(1,3):\n",
    "    with gzip.open('./web_application/datasets/prod_cosine_' + str(n) + '.json.gz', 'rb') as fp:\n",
    "        json_bytes = fp.read()\n",
    "    data_2.update(json.loads(json_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code from Heroku trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('./datasets/prod_cosine.json.gz', 'rb') as fp:\n",
    "    json_bytes = fp.read()\n",
    "data = json.loads(json_bytes)\n",
    "\n",
    "with gzip.open('./datasets/prod_images.json.gz', 'rb') as fi:\n",
    "    json_img = fi.read()   \n",
    "images = json.loads(json_img)\n",
    "\n",
    "with open('./datasets/prod_cosine.json', 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "with open('./datasets/prod_images.json', 'r') as fi:\n",
    "    images = json.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "CRC check failed 0xd16ea20 != 0x994bc147",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c43eaa404268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./web_application/datasets/prod_cosine.json.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;31m# Check the CRC and file size, and set the flag so we read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;31m# a new member\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_eof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_member\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                 self._decompressor = self._decomp_factory(\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m_read_eof\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcrc32\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             raise OSError(\"CRC check failed %s != %s\" % (hex(crc32),\n\u001b[0;32m--> 501\u001b[0;31m                                                          hex(self._crc)))\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream_size\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xffffffff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Incorrect length of data produced\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: CRC check failed 0xd16ea20 != 0x994bc147"
     ]
    }
   ],
   "source": [
    "with gzip.open('./web_application/datasets/prod_cosine.json.gz', 'rb') as fp:\n",
    "    json_bytes = fp.read()\n",
    "hie = json.loads(json_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "CRC check failed 0xd16ea20 != 0x994bc147",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-4f34ccff6b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./web_application/datasets/prod_cosine.json.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdecomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompressobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_WBITS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;31m# Check the CRC and file size, and set the flag so we read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;31m# a new member\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_eof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_member\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                 self._decompressor = self._decomp_factory(\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m_read_eof\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcrc32\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             raise OSError(\"CRC check failed %s != %s\" % (hex(crc32),\n\u001b[0;32m--> 501\u001b[0;31m                                                          hex(self._crc)))\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream_size\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xffffffff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Incorrect length of data produced\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: CRC check failed 0xd16ea20 != 0x994bc147"
     ]
    }
   ],
   "source": [
    "with gzip.open('./web_application/datasets/prod_cosine.json.gz', 'rb') as fp:\n",
    "    decomp = zlib.decompressobj(16+zlib.MAX_WBITS)\n",
    "    data = decomp.decompress(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hie.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "367px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
